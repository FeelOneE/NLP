{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      starScore                                              title\n",
       "0             5  쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...\n",
       "1             5  화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...\n",
       "2             5  대용량에 헐 감동입니다 1개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔...\n",
       "3             4  아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...\n",
       "4             5  프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...\n",
       "...         ...                                                ...\n",
       "9995          5                                       이번엔 제대로 왔어용!\n",
       "9996          5                                         덩치가 큰게 좋네요\n",
       "9997          5                                         좋아요~ 많이파세요\n",
       "9998          3                                           빠름배송 좋아요\n",
       "9999          5                                          잘받았습니다~^^\n",
       "\n",
       "[10000 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>starScore</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>대용량에 헐 감동입니다 1개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>5</td>\n      <td>이번엔 제대로 왔어용!</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>5</td>\n      <td>덩치가 큰게 좋네요</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>5</td>\n      <td>좋아요~ 많이파세요</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>3</td>\n      <td>빠름배송 좋아요</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>5</td>\n      <td>잘받았습니다~^^</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "#df = pd.DataFrame(result)\n",
    "df = pd.read_csv('review_data.csv')\n",
    "#df.to_csv('review_data.csv',sep=',', na_rep='NaN')\n",
    "df.describe\n",
    "df[['starScore','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       clean_content  label\n",
       "0  쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...      1\n",
       "1  화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...      1\n",
       "2  대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서...      1\n",
       "3  아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...      0\n",
       "4  프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...      1\n",
       "5  대이고 건성민감건성피부에  슬프면 앙대는데짐승용량착한가격부담없이 닥토스퇄마스크 트러...      1\n",
       "6  다른분 말처럼 향이 강하네요발랐을때 깔끔한 느낌보다는 살짝 텁텁한 느낌이었어요 그렇...      0\n",
       "7  스킨은 프레쥬만 써요작년에 접촉성 피부염으로 고생했을 때 연고고 레이저고 아무 소용...      1\n",
       "8  닦토용으로 주문해 봤어요 저렴한데 가격대비 꽤 괜찮은것 같아요쑥향이 별로 안난다는 ...      1\n",
       "9  쑥이라 해서 쑥 향이 나는 줄 알았지만 쑥향은 전혀 없고 보통 화장수의 향입니다엄청...      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_content</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>대이고 건성민감건성피부에  슬프면 앙대는데짐승용량착한가격부담없이 닥토스퇄마스크 트러...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>다른분 말처럼 향이 강하네요발랐을때 깔끔한 느낌보다는 살짝 텁텁한 느낌이었어요 그렇...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>스킨은 프레쥬만 써요작년에 접촉성 피부염으로 고생했을 때 연고고 레이저고 아무 소용...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>닦토용으로 주문해 봤어요 저렴한데 가격대비 꽤 괜찮은것 같아요쑥향이 별로 안난다는 ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>쑥이라 해서 쑥 향이 나는 줄 알았지만 쑥향은 전혀 없고 보통 화장수의 향입니다엄청...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# cleasing 함수 \n",
    "import regex as re\n",
    "import numpy as np\n",
    "def cleasing(text):\n",
    "    repl =''\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)' # 자음, 모음 제거\n",
    "    text = re.sub(pattern= pattern, repl=repl, string=text)\n",
    "    #pattern = '[^\\w\\s]' # 특수기호 제거\n",
    "    pattern = '[^가-히\\s]' # 특수기호 제거\n",
    "    text = re.sub(pattern= pattern, repl=repl, string=text)\n",
    "    pattern = '<[^>]*>' # html 제거\n",
    "    text = re.sub(pattern = pattern, repl='',string=text)\n",
    "    return text\n",
    "df['length'] = df.content.str.len()\n",
    "df['label'] = np.where(df['starScore']<5, 0, 1)\n",
    "df['clean_content'] = df['content'].map(lambda x: cleasing(x))\n",
    "df2 = df[ df.length > 30 ] \n",
    "df2 = df2[['clean_content','label']]\n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                          clean_content  label check_content\n",
       "0     쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...      1              \n",
       "1     화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...      1              \n",
       "2     대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서...      1              \n",
       "3     아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...      0              \n",
       "4     프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...      1              \n",
       "...                                                 ...    ...           ...\n",
       "9985  좋아요 재구맵니다 저번에는 유통기한 거의 다 된거 보내주셨는데 거의 다 쓰고 발견했...      0              \n",
       "9986                            확실히 양도 많고 구성도 좋네요 만족합니다      1              \n",
       "9987                               저렴한가격에  괜찮고좋습니다대박나셔요      1              \n",
       "9990  잘 받았어요 잘 받았어요  아직 써보진 않았지만 기대됩니다 잘 쓰겠습니다 잘 받았어...      0              \n",
       "9994  좋아요 대용량이라서 스킨팩하기에 너무 좋아요 개인차는 잇겟지만 향도 괜찮네요 정말 ...      0              \n",
       "\n",
       "[4881 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_content</th>\n      <th>label</th>\n      <th>check_content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서...</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...</td>\n      <td>0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9985</th>\n      <td>좋아요 재구맵니다 저번에는 유통기한 거의 다 된거 보내주셨는데 거의 다 쓰고 발견했...</td>\n      <td>0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9986</th>\n      <td>확실히 양도 많고 구성도 좋네요 만족합니다</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9987</th>\n      <td>저렴한가격에  괜찮고좋습니다대박나셔요</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9990</th>\n      <td>잘 받았어요 잘 받았어요  아직 써보진 않았지만 기대됩니다 잘 쓰겠습니다 잘 받았어...</td>\n      <td>0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>9994</th>\n      <td>좋아요 대용량이라서 스킨팩하기에 너무 좋아요 개인차는 잇겟지만 향도 괜찮네요 정말 ...</td>\n      <td>0</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>4881 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "df2['check_content'] = ''\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-74-b9cd282edc4b>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['check_content'][index] = spell_checker.check(item['clean_content']).checked\n",
      "error occur! :  Invalid control character at: line 1 column 225 (char 224)\n",
      "그부분만 조금 아쉬울뿐 용량는 짱짱걸\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                       clean_content  label  \\\n",
       "0  쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...      1   \n",
       "1  화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...      1   \n",
       "2  대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서...      1   \n",
       "3  아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...      0   \n",
       "4  프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...      1   \n",
       "5  대이고 건성민감건성피부에  슬프면 앙대는데짐승용량착한가격부담없이 닥토스퇄마스크 트러...      1   \n",
       "6  다른분 말처럼 향이 강하네요발랐을때 깔끔한 느낌보다는 살짝 텁텁한 느낌이었어요 그렇...      0   \n",
       "7  스킨은 프레쥬만 써요작년에 접촉성 피부염으로 고생했을 때 연고고 레이저고 아무 소용...      1   \n",
       "8  닦토용으로 주문해 봤어요 저렴한데 가격대비 꽤 괜찮은것 같아요쑥향이 별로 안난다는 ...      1   \n",
       "9  쑥이라 해서 쑥 향이 나는 줄 알았지만 쑥향은 전혀 없고 보통 화장수의 향입니다엄청...      0   \n",
       "\n",
       "                                       check_content  \n",
       "0  쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침저녁으로 ...  \n",
       "1  화장품 상자에 한 번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는...  \n",
       "2  대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍하셔서 ...  \n",
       "3  아직 사용 전인데 오자마자 간병 이모님이 머냐고 물어보셔서 약쑥 스킨이라고  하니 ...  \n",
       "4  프레쥬 진정 토너 여름에 시원하게 토너 팩하기 좋아요 향은 쑥 냄새보다는 시트러스 ...  \n",
       "5  대이고 건성 민감 건성피부에  슬프면 앙대는데 짐승 용량 착한 가격 부담 없이 닥토...  \n",
       "6  다른 분 말처럼 향이 강하네요 발랐을 때 깔끔한 느낌보다는 살짝 텁텁한 느낌이었어요...  \n",
       "7  스킨은 프레쥬만 써요 작년에 접촉성 피부염으로 고생했을 때 연고 고 레이 저고 아무...  \n",
       "8  닦도 용으로 주문해 봤어요 저렴한데 가격 대비 꽤 괜찮은 것 같아요 쑥 향이 별로 ...  \n",
       "9  쑥이라 해서 쑥 향이 나는 줄 알았지만 쑥 향은 전혀 없고 보통 화장수의 향입니다 ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_content</th>\n      <th>label</th>\n      <th>check_content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로...</td>\n      <td>1</td>\n      <td>쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침저녁으로 ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 ...</td>\n      <td>1</td>\n      <td>화장품 상자에 한 번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서...</td>\n      <td>1</td>\n      <td>대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍하셔서 ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번...</td>\n      <td>0</td>\n      <td>아직 사용 전인데 오자마자 간병 이모님이 머냐고 물어보셔서 약쑥 스킨이라고  하니 ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열...</td>\n      <td>1</td>\n      <td>프레쥬 진정 토너 여름에 시원하게 토너 팩하기 좋아요 향은 쑥 냄새보다는 시트러스 ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>대이고 건성민감건성피부에  슬프면 앙대는데짐승용량착한가격부담없이 닥토스퇄마스크 트러...</td>\n      <td>1</td>\n      <td>대이고 건성 민감 건성피부에  슬프면 앙대는데 짐승 용량 착한 가격 부담 없이 닥토...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>다른분 말처럼 향이 강하네요발랐을때 깔끔한 느낌보다는 살짝 텁텁한 느낌이었어요 그렇...</td>\n      <td>0</td>\n      <td>다른 분 말처럼 향이 강하네요 발랐을 때 깔끔한 느낌보다는 살짝 텁텁한 느낌이었어요...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>스킨은 프레쥬만 써요작년에 접촉성 피부염으로 고생했을 때 연고고 레이저고 아무 소용...</td>\n      <td>1</td>\n      <td>스킨은 프레쥬만 써요 작년에 접촉성 피부염으로 고생했을 때 연고 고 레이 저고 아무...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>닦토용으로 주문해 봤어요 저렴한데 가격대비 꽤 괜찮은것 같아요쑥향이 별로 안난다는 ...</td>\n      <td>1</td>\n      <td>닦도 용으로 주문해 봤어요 저렴한데 가격 대비 꽤 괜찮은 것 같아요 쑥 향이 별로 ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>쑥이라 해서 쑥 향이 나는 줄 알았지만 쑥향은 전혀 없고 보통 화장수의 향입니다엄청...</td>\n      <td>0</td>\n      <td>쑥이라 해서 쑥 향이 나는 줄 알았지만 쑥 향은 전혀 없고 보통 화장수의 향입니다 ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "from py_hanspell.hanspell import spell_checker\n",
    "check_result = []\n",
    "\n",
    "for index, item in df2.iterrows():\n",
    "    try:\n",
    "        df2['check_content'][index] = spell_checker.check(item['clean_content']).checked\n",
    "    except Exception as e: \n",
    "        print(\"error occur! : \",e)\n",
    "        print(item['clean_content'])\n",
    "        continue\n",
    "\n",
    "df2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로 매일 매일 쓰기에 부담이 없고 좋습니다자연약쑥 진정 토너라 자극없이 쓰기에도 좋고 녹차 루이보스 캐모마일 쑥 페퍼민트 로즈마리 유칼리투스잎이 들어간 그린 허브 성분이라 피부 진정에도 도움이 되는거 같아요',\n",
       "  1],\n",
       " ['화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 플라스틱 용기인데  용량이 커서  한참 쓸 수 있어 좋네요 뚜껑을 열었을때  향기 좋네 하는 느낌이 없으니 향을 중요시  하는 분은  좋아하지  않을 듯 하네요바르고 조금 시간이 지나면  향이  없어지는 것  같아요용기에 적혀 있는 글씨가 너무 적어  안보였는데 세트 구입했더니 앰플인지 뭔지 모르겠는데  작은 샘플이 개가 있네요  싼 가격에  이 구성이면  좋네요',\n",
       "  1],\n",
       " ['대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서 많이 하셔도 흡수는 잘됩니다 저는 얼굴에 흡수가 안되는 타입인데 제품이 흡수 잘되고요 약간의 알콜냄새는 살짝 스치는 정도 입니다 코로나에 다들 든데 이 가격에 정말 감사합니다 마구 쓰시고 싶은 분은 구입 하시고 쫀질한 느낌과 깊은 느낌분들은 살짝 고민하시고 클렌징으로 쓰고 싶다 하시는 분들은 차 쓰시고 고가의 스킨을 바르시는것도 좋을듯 합니다',\n",
       "  1],\n",
       " ['아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번 보자고 해서 뚜껑 열어서 향 맞아보고 손에 조금만 부어 보라고 해서 부었더니 발라보시더니 금방 흡수되고 촉촉하다고 하시며 얼마냐고 물어 보셔서 써보시라고 그냥 하나 드렸네요 방에 환자도 뭔데 그리 크냐고 하시면서 어떻게 사냐고 물어보시고 다들 관심 보이네요 각질제거가 된다니 일단 닦토로 써보고 조으면 계속 사서 써보려구요',\n",
       "  0],\n",
       " ['프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열 레몬향이 나는 편이구요대용량인데다 이라서 한통은 냉장고에 넣어놓고 자외선 높은 날에 진정용으로 팩하면 시원하고 진정도 되고 좋습니다가격이 워낙 저렴해서 크게 기대 안했는데 피지 많이 올라오는 여름에 쓰기 좋은 토너입니다',\n",
       "  1]]"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "dataset_all = [ ['',0] for _ in range(len(df2)+1) ]\n",
    "#print(dataset_all[0][0])\n",
    "index = 0\n",
    "for indexs, row in df2.iterrows():\n",
    "    #print(index)\n",
    "    dataset_all[index][0] = row['clean_content']\n",
    "    dataset_all[index][1] = row['label']\n",
    "    index = index+1\n",
    "\n",
    "dataset_all[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2929, 1953)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "data_length = len(dataset_all)\n",
    "train_length = int(data_length*0.6)\n",
    "\n",
    "dataset_train = dataset_all[0:train_length]\n",
    "dataset_test = dataset_all[train_length:data_length]\n",
    "len(dataset_train),len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting mxnet\n",
      "  Downloading mxnet-1.8.0.post0-cp38-cp38-macosx_10_13_x86_64.whl (34.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.9 MB 1.4 MB/s \n",
      "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /opt/anaconda3/lib/python3.8/site-packages (from mxnet) (2.24.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /opt/anaconda3/lib/python3.8/site-packages (from mxnet) (1.19.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
      "Collecting gluonnlp\n",
      "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
      "\u001b[K     |████████████████████████████████| 344 kB 1.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/anaconda3/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (4.50.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/anaconda3/lib/python3.8/site-packages (from gluonnlp) (1.19.2)\n",
      "Requirement already satisfied: cython in /opt/anaconda3/lib/python3.8/site-packages (from gluonnlp) (0.29.21)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from gluonnlp) (20.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging->gluonnlp) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from packaging->gluonnlp) (1.15.0)\n",
      "Building wheels for collected packages: gluonnlp\n",
      "  Building wheel for gluonnlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp38-cp38-macosx_10_9_x86_64.whl size=461641 sha256=e69b0216d0f9c40ea33a0cc92a3529081120b32c6e24a9411b25e86a4249f8c9\n",
      "  Stored in directory: /Users/icn/Library/Caches/pip/wheels/b6/93/9d/2237550c409eb3ed725d6302b7897ddd9a037b40cef66dcd9c\n",
      "Successfully built gluonnlp\n",
      "Installing collected packages: gluonnlp\n",
      "Successfully installed gluonnlp-0.10.0\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.8/site-packages (0.1.96)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.8/site-packages (4.6.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: sacremoses in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.8/site-packages (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet\n",
    "!pip install gluonnlp pandas tqdm\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
      "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /private/var/folders/b2/zt_25g6x7tdcc_wt2qy0hv600000gn/T/pip-req-build-685syp3g\n",
      "Building wheels for collected packages: kobert\n",
      "  Building wheel for kobert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12705 sha256=4a780c2392ba7a141bc45a9e89cbb713dbe3bc205ac131d7e4ade90b2fb4bcf6\n",
      "  Stored in directory: /private/var/folders/b2/zt_25g6x7tdcc_wt2qy0hv600000gn/T/pip-ephem-wheel-cache-5zoo_j77/wheels/bf/5f/74/81bf3a1332130eb6629ecf58876a8746b77021e7d7b0638e91\n",
      "Successfully built kobert\n",
      "Installing collected packages: kobert\n",
      "Successfully installed kobert-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7772285171713691435]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cpu', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "device = torch.device(\"cpu:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[██████████████████████████████████████████████████]\n",
      "[██████████████████████████████████████████████████]\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-06-27 14:22:40--  https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/374ftkec978br3d/ratings_train.txt [following]\n",
      "--2021-06-27 14:22:41--  https://www.dropbox.com/s/dl/374ftkec978br3d/ratings_train.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc249f29be8bff52f0058603542d.dl.dropboxusercontent.com/cd/0/get/BRNj8wi09R_6yIDIp6JOPcrpmk3qHdL-GCHyWacX-slFtzWmwdBQRC8-Kwx8DBZb29xbpSgfSb9JTBCSXeOWhbCQL5vJ28Bun-MOEfLqAEB5_0U_vi3VUh1LMVgZTUah3gdsvflYN63ovvriCk17ZFHs/file?dl=1# [following]\n",
      "--2021-06-27 14:22:42--  https://uc249f29be8bff52f0058603542d.dl.dropboxusercontent.com/cd/0/get/BRNj8wi09R_6yIDIp6JOPcrpmk3qHdL-GCHyWacX-slFtzWmwdBQRC8-Kwx8DBZb29xbpSgfSb9JTBCSXeOWhbCQL5vJ28Bun-MOEfLqAEB5_0U_vi3VUh1LMVgZTUah3gdsvflYN63ovvriCk17ZFHs/file?dl=1\n",
      "Resolving uc249f29be8bff52f0058603542d.dl.dropboxusercontent.com (uc249f29be8bff52f0058603542d.dl.dropboxusercontent.com)... 162.125.80.15\n",
      "Connecting to uc249f29be8bff52f0058603542d.dl.dropboxusercontent.com (uc249f29be8bff52f0058603542d.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14628807 (14M) [application/binary]\n",
      "Saving to: `ratings_train.txt?dl=1'\n",
      "\n",
      "ratings_train.txt?d 100%[===================>]  13.95M   552KB/s    in 33s     \n",
      "\n",
      "2021-06-27 14:23:17 (437 KB/s) - `ratings_train.txt?dl=1' saved [14628807/14628807]\n",
      "\n",
      "--2021-06-27 14:23:17--  https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.80.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.80.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/dl/977gbwh542gdy94/ratings_test.txt [following]\n",
      "--2021-06-27 14:23:19--  https://www.dropbox.com/s/dl/977gbwh542gdy94/ratings_test.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucea66af96226a7332917fd34ac2.dl.dropboxusercontent.com/cd/0/get/BROeB5bUsb7J_JDXZ_m9j03I-u6E3VcEjeYUIhiUzLFRHOtins8Lu1JMiRbNKX3cFwGxFgumWxtnu0FqCrPqWReOJO_R6K2A-4bo_KSAGqFqR4S-mW6IDeAx-2BRC5t19cJdbyo2TkKYp_qEVP5mQJnC/file?dl=1# [following]\n",
      "--2021-06-27 14:23:19--  https://ucea66af96226a7332917fd34ac2.dl.dropboxusercontent.com/cd/0/get/BROeB5bUsb7J_JDXZ_m9j03I-u6E3VcEjeYUIhiUzLFRHOtins8Lu1JMiRbNKX3cFwGxFgumWxtnu0FqCrPqWReOJO_R6K2A-4bo_KSAGqFqR4S-mW6IDeAx-2BRC5t19cJdbyo2TkKYp_qEVP5mQJnC/file?dl=1\n",
      "Resolving ucea66af96226a7332917fd34ac2.dl.dropboxusercontent.com (ucea66af96226a7332917fd34ac2.dl.dropboxusercontent.com)... 162.125.80.15\n",
      "Connecting to ucea66af96226a7332917fd34ac2.dl.dropboxusercontent.com (ucea66af96226a7332917fd34ac2.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4893335 (4.7M) [application/binary]\n",
      "Saving to: `ratings_test.txt?dl=1'\n",
      "\n",
      "ratings_test.txt?dl 100%[===================>]   4.67M   547KB/s    in 12s     \n",
      "\n",
      "2021-06-27 14:23:34 (388 KB/s) - `ratings_test.txt?dl=1' saved [4893335/4893335]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "#!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
    "#dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['쑥 들어간 제품들을 평소에 좋아해서 쑥 화장품으로 대부분 쓰려고 해요 아침 저녁으로 매일 매일 쓰기에 부담이 없고 좋습니다자연약쑥 진정 토너라 자극없이 쓰기에도 좋고 녹차 루이보스 캐모마일 쑥 페퍼민트 로즈마리 유칼리투스잎이 들어간 그린 허브 성분이라 피부 진정에도 도움이 되는거 같아요',\n",
       "  1],\n",
       " ['화장품 상자에 한번 더 뽁뽁이  포장으로  꼼꼼하게 담아져 있었고  화장품 용기는 플라스틱 용기인데  용량이 커서  한참 쓸 수 있어 좋네요 뚜껑을 열었을때  향기 좋네 하는 느낌이 없으니 향을 중요시  하는 분은  좋아하지  않을 듯 하네요바르고 조금 시간이 지나면  향이  없어지는 것  같아요용기에 적혀 있는 글씨가 너무 적어  안보였는데 세트 구입했더니 앰플인지 뭔지 모르겠는데  작은 샘플이 개가 있네요  싼 가격에  이 구성이면  좋네요',\n",
       "  1],\n",
       " ['대용량에 헐 감동입니다 개는 지인도 팍팍 쓰라고 선물했어요이건 화장솜에 듬뿍 하셔서 많이 하셔도 흡수는 잘됩니다 저는 얼굴에 흡수가 안되는 타입인데 제품이 흡수 잘되고요 약간의 알콜냄새는 살짝 스치는 정도 입니다 코로나에 다들 든데 이 가격에 정말 감사합니다 마구 쓰시고 싶은 분은 구입 하시고 쫀질한 느낌과 깊은 느낌분들은 살짝 고민하시고 클렌징으로 쓰고 싶다 하시는 분들은 차 쓰시고 고가의 스킨을 바르시는것도 좋을듯 합니다',\n",
       "  1],\n",
       " ['아직 사용전인데 오자마자 간병이모님이 머냐고 물어 보셔서 약쑥스킨이라고  하니 한번 보자고 해서 뚜껑 열어서 향 맞아보고 손에 조금만 부어 보라고 해서 부었더니 발라보시더니 금방 흡수되고 촉촉하다고 하시며 얼마냐고 물어 보셔서 써보시라고 그냥 하나 드렸네요 방에 환자도 뭔데 그리 크냐고 하시면서 어떻게 사냐고 물어보시고 다들 관심 보이네요 각질제거가 된다니 일단 닦토로 써보고 조으면 계속 사서 써보려구요',\n",
       "  0],\n",
       " ['프레쥬 진정토너 여름에 시원하게 토너팩 하기 좋아요 향은 쑥 냄새보다는 시트러스계열 레몬향이 나는 편이구요대용량인데다 이라서 한통은 냉장고에 넣어놓고 자외선 높은 날에 진정용으로 팩하면 시원하고 진정도 되고 좋습니다가격이 워낙 저렴해서 크게 기대 안했는데 피지 많이 올라오는 여름에 쓰기 좋은 토너입니다',\n",
       "  1]]"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "dataset_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['굳 ㅋ', '1'],\n",
       " ['GDNTOPCLASSINTHECLUB', '0'],\n",
       " ['뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아', '0'],\n",
       " ['지루하지는 않은데 완전 막장임... 돈주고 보기에는....', '0'],\n",
       " ['3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??', '0']]"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "dataset_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 5\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([   2,  517, 6778, 1806, 4158, 5938, 4848, 6896, 4207, 7850,  517,\n",
       "        6778, 5119, 7078, 1647, 3084, 6061, 4998, 6999, 3130, 3991, 7078,\n",
       "        1996, 1996, 3084, 5579, 2428, 3271, 4204, 6701, 7147, 6928, 6846,\n",
       "        6778, 4360, 7227, 4737, 5691, 6003, 3888, 6883, 3084, 5561, 6901,\n",
       "        4204, 5439, 1494, 7389, 1895, 7096, 6364, 6664, 4643, 6213, 6141,\n",
       "        7126,  517, 6778, 4829, 7706, 6263, 7659,  517,    3], dtype=int32),\n",
       " array(64, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 1)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([   2, 3942, 6288, 6827, 5703, 2613, 7207, 7116, 4204, 7088, 5377,\n",
       "        6003,  517, 6266, 6857, 6853, 7096, 1952, 3422, 6779, 5405, 5703,\n",
       "           3,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
       " array(23, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 1)"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-114-e6a38b13095b>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=46.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5483e6e98fd406bb3e75a35afb32599"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-e6a38b13095b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                                     \u001b[0;31m# Set miniters to correspond to maxinterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                                     \u001b[0mminiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_it\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmaxinterval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdelta_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m                             \u001b[0;32melif\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m                                 \u001b[0;31m# EMA-weight miniters to converge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                 \u001b[0;31m# towards the timeframe of mininterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  }
 ]
}